{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Top YouTube Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open HTML watch-history file from Google Takeout\n",
    "soup = BeautifulSoup(open('path\\to\\your\\file.html', encoding='utf8'), 'html.parser')\n",
    "\n",
    "# Can take sometime to load. Trim your file first if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023    # for my analysis I was only interested in 2023's history. If you'd like more, change this line to the earliest year you'd like to include\n",
    "\n",
    "stop_at = str(year - 1) + ', '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the outer cells\n",
    "outer_cells = soup.find_all('div', class_='outer-cell')\n",
    "\n",
    "data = []\n",
    "\n",
    "# Initial functions for following loop\n",
    "def get_link(links, index):\n",
    "    return links[index].get('href') if len(links) > index else None\n",
    "\n",
    "def get_date(vid_info):\n",
    "    return vid_info.find_all('br')[-1].next_sibling.strip()\n",
    "\n",
    "# Retrieve data from HTML\n",
    "for div_tag in outer_cells:\n",
    "    vid_info = div_tag.find(class_=\"content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1\")\n",
    "    caption = div_tag.find(class_=\"content-cell mdl-cell mdl-cell--12-col mdl-typography--caption\")\n",
    "    vid_type = vid_info.contents[0].get_text().strip()\n",
    "\n",
    "    if vid_type == 'Watched':\n",
    "        date = get_date(vid_info)\n",
    "        if stop_at in date:\n",
    "            break\n",
    "        \n",
    "        title = vid_info.contents[1].get_text().strip()\n",
    "        links = vid_info.find_all('a', href=True)\n",
    "        vid_link = get_link(links, 0)\n",
    "        channel_link = get_link(links, 1)\n",
    "        channel_text = vid_info.contents[3].get_text().strip()\n",
    "        channel = 'Video has been private' if channel_text == date else channel_text\n",
    "        ad = caption.contents[7].get_text().strip()\n",
    "\n",
    "    elif vid_type == 'Answered survey question':\n",
    "        date = get_date(vid_info)\n",
    "        if stop_at in date:\n",
    "            break\n",
    "        title = vid_info.contents[0].get_text().strip()\n",
    "        channel = 'None'\n",
    "        ad = 'Survey'\n",
    "        channel_link = None\n",
    "\n",
    "    elif vid_type == 'Watched a video that has been removed':\n",
    "        date = get_date(vid_info)\n",
    "        if stop_at in date:\n",
    "            break\n",
    "        title = vid_info.contents[0].get_text().strip()\n",
    "        channel = 'Unknown'\n",
    "        channel_link = None\n",
    "        ad = 'No'\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    row_data = [title, vid_link, channel, channel_link, date, ad]\n",
    "    data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the extracted data\n",
    "history_df = pd.DataFrame(data, columns=['title', 'vid_link', 'channel', 'channel_link', 'date', 'ad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing to drop duplicates on link because some channels use the same title for live streams, and I'm choosing not to count revisiting videos since I did this often for reference\n",
    "no_dups = history_df.drop_duplicates(subset='vid_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's finally get those top channels\n",
    "top_5_df = no_dups.channel.value_counts().sort_values(ascending=False).head(5).reset_index().rename(columns={'index': 'channel', 'channel': 'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm your top channels don't include ads, etc\n",
    "top_5_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's make it pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get channel links so we can get profile pictures\n",
    "top_5_df = pd.merge(top_5_df, history_df[['channel', 'channel_link']], on='channel', how='left').drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "background_image_paths = [\n",
    "    'background_images/1.jpg',\n",
    "    'background_images/2.jpg'\n",
    "]\n",
    "\n",
    "custom_font_path = 'fonts/youtube-sans-light.ttf'\n",
    "title_font_path = 'fonts/youtube-sans-medium.ttf'\n",
    "number_font_path = 'fonts/youtube-sans-bold.ttf'\n",
    "\n",
    "# Image dimensions\n",
    "image_width = 240\n",
    "image_height = 240\n",
    "\n",
    "# Font sizes\n",
    "font_size_large = 50\n",
    "font_size_small = 40\n",
    "title_font_size = 90\n",
    "number_font_size = 100\n",
    "\n",
    "# Load fonts\n",
    "channel_font = ImageFont.truetype(font=custom_font_path, size=font_size_large)\n",
    "watched_font = ImageFont.truetype(font=custom_font_path, size=font_size_small)\n",
    "title_font = ImageFont.truetype(font=title_font_path, size=title_font_size)\n",
    "number_font = ImageFont.truetype(font=number_font_path, size=number_font_size)\n",
    "\n",
    "# Iterate over background image paths\n",
    "for background_image_path in background_image_paths:\n",
    "    # Load background image\n",
    "    background_image = Image.open(background_image_path)\n",
    "   \n",
    "    # Starting coordinates\n",
    "    x_offset = 125\n",
    "    y_offset = 300\n",
    "\n",
    "    # Iterate over top_5 DataFrame\n",
    "    for index, row in top_5_df.iterrows():\n",
    "        channel = row['channel']\n",
    "        url = row['channel_link']\n",
    "        count = row['counts']\n",
    "\n",
    "        response = requests.get(url)\n",
    "        html_content = response.content.decode('utf-8')\n",
    "\n",
    "        # Find the meta tag containing og:title and the associated image link\n",
    "        pattern = r'<meta property=\"og:title\" content=\".*?\"><link rel=\"image_src\" href=\"(.*?)\">'\n",
    "        match = re.search(pattern, html_content)\n",
    "\n",
    "        if match:\n",
    "            image_link = match.group(1)\n",
    "            # Download the image\n",
    "            image_response = requests.get(image_link)\n",
    "            try:\n",
    "                # Save the image temporarily\n",
    "                with open('temp_image.jpg', 'wb') as f:\n",
    "                    f.write(image_response.content)\n",
    "                image_path = 'temp_image.jpg'\n",
    "                \n",
    "                # Load and resize the image\n",
    "                image = Image.open(image_path).resize((image_width, image_height))\n",
    "                \n",
    "                # Define fill color based on pass\n",
    "                if background_image_paths.index(background_image_path) == 1:\n",
    "                    fill_color = (255, 255, 255)  # White\n",
    "                else:\n",
    "                    fill_color = (0, 0, 0)  # Black\n",
    "\n",
    "                # Add title text\n",
    "                title_text = \"My Top YouTube Channels\"\n",
    "                title_text_position = (55, 150)\n",
    "                draw = ImageDraw.Draw(background_image)\n",
    "                draw.text(title_text_position, title_text, font=title_font, fill=fill_color)\n",
    "\n",
    "                # Draw number text\n",
    "                number_text = str(index + 1)\n",
    "                number_text_position = (x_offset, y_offset)\n",
    "                draw.text(number_text_position, number_text, font=number_font, fill=fill_color)\n",
    "\n",
    "                # Paste the image on the background image\n",
    "                background_image.paste(image, (x_offset + number_font_size, y_offset))\n",
    "\n",
    "                # Draw channel text\n",
    "                channel_text = channel\n",
    "                channel_text_position = (x_offset + image_width + 135, y_offset)\n",
    "                draw.text(channel_text_position, channel_text, font=channel_font, fill=fill_color)\n",
    "\n",
    "                # Draw count text\n",
    "                count_text = f'{count} videos watched'\n",
    "                count_text_position = (x_offset + image_width + 135, channel_text_position[1] + font_size_large)\n",
    "                draw.text(count_text_position, count_text, font=watched_font, fill=fill_color)\n",
    "\n",
    "                # Add subtext\n",
    "                subtext = \"coded by github.com/apancoast\".upper()\n",
    "                subtext_position = (450, background_image.height - 150)\n",
    "                draw.text(subtext_position, subtext, font=watched_font, fill=fill_color)\n",
    "                \n",
    "                # Delete the temporary image file\n",
    "                os.remove(image_path)\n",
    "\n",
    "                y_offset += 280\n",
    "            except Exception as e:\n",
    "                print(f'Error processing image from {image_path}: {str(e)}')\n",
    "        else:\n",
    "            print(f'Image link not found in the HTML content of {url}')\n",
    "\n",
    "    # Save the final image\n",
    "    output_path = 'result_image_' + str(background_image_paths.index(background_image_path) + 1) + '.jpg'\n",
    "    background_image.save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
